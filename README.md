# Text Mining and Tuning Hyperparameter for Classification Task


## Project Overview
This project explores and maximizes the performance of text classification models through **text mining** and **hyperparameter tuning**. The primary goal is to identify the best combination of text vectorization methods and machine learning algorithms for effective text classification.

Key highlights:
- Two machine learning algorithms: **Support Vector Machine (SVM)** and **Random Forest**.
- Two text representation methods: **TF-IDF** and **Bag of Words (BoW)**.
- Achieved **96% accuracy** using a combination of **TF-IDF** and **Linear Kernel SVM**.

This project also provides comparisons between different model combinations, highlighting their respective strengths and weaknesses.

## Features
- Text preprocessing: tokenization, stopword removal, and vectorization.
- Implementation of multiple machine learning models.
- Hyperparameter tuning using **GridSearchCV**.
- Performance evaluation using accuracy metrics and confusion matrices.

## Key Results
- Best accuracy: **96%**, achieved with TF-IDF and Linear Kernel SVM.
- Comprehensive performance analysis of SVM and Random Forest models.
- Insightful comparisons between TF-IDF and BoW vectorization methods.

## Tools and Libraries Used
- **Programming Language**: Python
- **Libraries**:
  - `scikit-learn` for machine learning and model evaluation
  - `NLTK` and `spaCy` for text preprocessing
  - `Pandas` and `NumPy` for data manipulation
  - `Matplotlib` and `Seaborn` for visualization

## Results and Analysis
![image](https://github.com/user-attachments/assets/f098d7e5-34f5-4055-b940-5a1f22b245a1)


The performance of the models was evaluated using various metrics, and the results are summarized as follows:

SVM with TF-IDF: Best performance with 96% accuracy.
